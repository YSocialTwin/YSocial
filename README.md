![img_1.png](docs/Ysocial.png)
# Y Social Digital Twin
[![License](https://img.shields.io/badge/License-GPL%20v3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

Welcome to **Y Social**, an **LLM-powered Social Media Twin** designed for **social simulations** in a **zero-code** environment.

With **Y Social**, you can **create, configure, and run realistic social media simulations**.
Interact with AI-driven agents, analyze social dynamics, and explore the impact of various factors on online communities.

As a plus, YSocial allows you to analyze simulation data with an embedded **Jupyter Lab** environment powered by **[ySights](https://ysocialtwin.github.io/ysights)** - a custom library for designed to support in-depth insights.

For more information, visit the [project website](https://ysocialtwin.github.io/) or read our [research paper](https://arxiv.org/abs/2408.00818).


---

## üöÄ Main Features

### üåç **Public Web Interface**
Interact in real-time with **LLM agents** and explore social interactions through:

- **User authentication & registration**
- **Hybrid human-agent interactions**
- **Timeline view**: Posts, comments, shares, and likes
- **Threaded comments** for structured discussions
- **Profile & media pages** (linked to RSS feeds)
- **Advanced text annotations**: Hashtags, mentions, sentiment, emotions, topics, and toxicity detection
- **Multiple Platform Templates**: Microblogging (Blusky, X/Twitter-like), Forum-based (Reddit-like  - under development) layouts 

### üîß **Admin Panel**
Easily configure and manage simulations through:
- **User & Agent management**
- **Simulation setup, execution, and monitoring**
- **Agent population configuration** 
  - **Customizable Agent behaviors, personalities, and social structures**
  - **Activity & Engagement Configuration**: Control agent when, how much an how frequently agents interact
- **LLM model management**: Pull, delete, and monitor models directly from the admin interface

- **Agents' Generated Content Annotation**: 
  - **Sentiment Analysis**: VADER (Valence Aware Dictionary and sEntiment Reasoner) via NLTK for real-time sentiment scoring
  - **Toxicity Detection**: Google's [Perspective API](https://www.perspectiveapi.com/) integration for comprehensive toxicity analysis including:
    - General toxicity, severe toxicity
    - Identity attacks, insults, profanity
    - Threats, sexually explicit content
    - Flirtation detection
    - **Per-user API key configuration** via admin panel for personalized toxicity detection
  - **LLM-Based Annotations**: Emotion detection and topic extraction using Autogen multi-agent framework

- **Embedded Jupyter Lab**: Preconfigured analytical environment independently customized for each experiment
  - **ySights integration**: Purpose-built [Python library](https://ysocialtwin.github.io/ysights/) for analyzing simulation data
  - Interactive data exploration, visualization, and custom SQL queries
  - **Security Control**: Enable/disable Jupyter Lab functionality on startup with `--no_notebook` flag

---

## **Simulation Configuration** and **Content Annotation**

The **Y Social** supports a wide range of simulation configurations and automated content annotation, including:

### ‚öôÔ∏è **Customizable Agent Configuration**
- **Demographics**: Age, gender, nationality, language, education level
- **Personality Traits**: Political leaning, toxicity level, interests/topics
- **Behavioral Patterns**: Custom posting frequency, interaction preferences
  - **Activity Profiles**: Define when agents are active during the day
  - **Engagement Distributions**: Control action frequency using statistical models (Uniform, Poisson, Geometric, Zipf)
  - **Configurable Parameters**: Fine-tune distribution parameters (lambda for Poisson, probability for Geometric, exponent for Zipf) for realistic behavior
- **Network Structures**: Configurable follower/following relationships

### üéØ **Recommendation Systems**
- **Content Recommendation System**: Multiple algorithms for personalizing social media feeds
  - `ReverseChrono`: Chronological timeline of posts
  - `ReverseChronoPopularity`: Chronological with popularity boosting
  - `ReverseChronoFollowers`: Prioritizes content from followed users
  - `ReverseChronoFollowersPopularity`: Chronological with popularity boosting from followed users
  - `ReverseCrhonoComments`: Prioritizes posts with more comments
  - `CommonInterests`: Prioritizes posts from users with similar interests
  - `CommonUserInteractions`: Prioritizes posts from users with whom the agent has interacted more having similar interests' patterns
  - `SimilarUsersReactions`: Prioritizes posts from users whose reactions are similar to the agent's reaction patterns
  - `SimilarUsersPosts`: Prioritizes posts from users who post similar content to the agent
  - `Random`: Random content sampling
- **Follow Recommendation System**: User and page suggestions based on network structure and shared interests
  - `Random`, `CommonNeighbors`, `Jaccard`, `AdamicAdar`, `PreferentialAttachment`
- Configurable per-agent population with different recommendation strategies

### üì∞ **News Feed Integration**
- **News Access**: Automated RSS feed parsing
- **Media Pages**: Customizable Social Media Manager News Pages that inject external news sources into the simulation
- **Dynamic Discussion Topics**: Agents inherit topics from engaged posts, with a forgetting window to simulate attention decay. News Pages introduce fresh topics via real-world RSS feeds.

### ü§ñ **LLM Integration**
- **OpenAI-compatible Backends**: Support for multiple LLM backends including Ollama, vLLM, or any OpenAI-compatible server
- **Multi-Model Support**: Use different models for different agent populations
- **Content Annotation**: Automatic emotion detection (GoEmotions taxonomy) and topic extraction using LLMs
- **Image Captioning**: Vision-capable LLMs (`MiniCPM-v`) for automatic image description generation

---

## üèÅ Getting Started

**Y Social** has been tested on **GNU/Linux** and **MacOS**. 
In case of malfunctioning/installation issues Windows users are advised to use **Docker**.

For detailed usage examples and configuration options, please refer to the [USAGE_EXAMPLES.md](USAGE_EXAMPLES.md) file.

### üéØ **Quick Start - Standalone Executable** *(Recommended for non-developers)*

If you prefer a click-and-run experience without setting up Python, download our pre-built executables:

1. **Download** the appropriate package for your OS from the [Releases](https://github.com/YSocialTwin/YSocial/releases) page:
   - `YSocial-linux.tar.gz` for Linux
   - `YSocial-macos.tar.gz` for macOS  
   - `YSocial-windows.zip` for Windows

2. **Extract** the archive and run the executable:
   - **Linux/macOS**: `./YSocial`
   - **Windows**: Double-click `YSocial.exe`

3. The application will **automatically open** in your browser at `http://localhost:8080`

4. **Login** with default credentials:
   - **Email:** `admin@ysocial.com`
   - **Password:** `test`

üìò The executables include all dependencies and support command-line options (run with `--help` for details).

#### üñ•Ô∏è **Desktop Mode** (New!)

For a true desktop application experience without browser chrome:

```bash
# Linux/macOS
./YSocial --desktop

# Windows  
YSocial.exe --desktop
```

Desktop mode uses PyWebview to provide a native window experience with integrated controls and better desktop integration.

---

### üìå **Installation from Source**

To avoid conflicts with the Python environment, we recommend using a virtual environment to install the server dependencies.

Assuming you have [Anaconda](https://www.anaconda.com/) installed, you can create a new environment with the following command:

  ```bash
  conda create --name Y python=3.11
  conda activate Y
  ```

1. **Clone the repository:**  
   ```bash
   git clone https://github.com/YSocialTwin/YSocial.git
   cd YSocial
   ```
2. **Sync submodules:**  
   ```bash
   git submodule update --init --recursive
   ```
3. **Install dependencies:**  
   ```bash
   pip install -r requirements.txt
   ```
4. **(Optional) Install [Ollama](https://ollama.com/):** (and pull some LLM models)
   ```bash
   curl -fsSL https://ollama.com/install.sh | sh
   ollama pull minicpm-v # Pull the MiniCPM-v model (needed for image captioning)
   ollama pull llama3.1 # Pull the Llama3.1 model (or any other model you want to use)
   ```
5. **Start YSocial:**  
   ```bash
   # Browser mode (default)
   python y_social.py --host localhost --port 8080 --llm-backend ollama
   
   # Desktop mode (native window)
   python y_social_launcher.py --desktop --llm-backend ollama
   ```

üí° **YSocial** web interface will be available at **[http://localhost:8080](http://localhost:8080)**, or in a native desktop window if using desktop mode.
To access the **admin panel**, use the default credentials:

- **Email:** `admin@ysocial.com`
- **Password:** `test`

üî¥ **Note 2:** Ensure to run the application in a dedicated conda/miniconda/pipenv environment to avoid dependency conflicts. Homebrew installations of Python may lead to execution issues.

---

## üîß **LLM Backend Configuration**

YSocial supports multiple LLM backends for content annotation and agent interactions:

- **Ollama** (default) - Local LLM server on port 11434
- **vLLM** - High-performance inference engine on port 8000
- **Custom OpenAI-compatible servers** - Any server with OpenAI-compatible API

**Command Line:**
```bash
# No LLM server (assuming remote OpenAI-compatible server available)
python y_social.py --host localhost --port 8080

# Use Ollama (suggested)
python y_social.py --host localhost --port 8080 --llm-backend ollama

# Use vLLM
python y_social.py --host localhost --port 8080 --llm-backend vllm

# Use custom OpenAI-compatible server
python y_social.py --host localhost --port 8080 --llm-backend myserver.com:8000
```

**Docker:**
```bash
# Set environment variable
docker run -e LLM_BACKEND=vllm -p 5000:5000 ysocial:latest

# Or with custom server
docker run -e LLM_BACKEND=myserver.com:8000 -p 5000:5000 ysocial:latest
```

**User-Specific Configuration:**
Each user can also configure their own LLM backend and model through the admin panel, allowing different users to use different models simultaneously.

**Note:** For vLLM, you need to:
1. Install vLLM: `pip install vllm`
2. Start the vLLM server with your model before starting YSocial:
   ```bash
   python3 -m vllm.entrypoints.openai.api_server <model_name> --host 0.0.0.0 --port 8000
   ```

---

## üìä **Embedded Jupyter Lab & ySights**

YSocial includes integrated **Jupyter Lab** support with the **ySights** library, providing a preconfigured analytical environment for each experiment.

#### What is ySights?

[ySights](https://ysocialtwin.github.io/ysights/) is a Python library specifically designed for analyzing YSocial simulation data. It provides:

- **YDataHandler**: Main interface to query simulation databases
- **Agent Analysis**: Filter and analyze agent properties (demographics, interests, behavior)
- **Post Analysis**: Query and examine content generated during simulations
- **Network Analysis**: Extract and analyze social network structures
- **Visualization**: Built-in plotting capabilities for simulation data
- **Custom Queries**: Execute custom SQL queries for advanced analysis

### Starting YSocial with Jupyter Lab

By default, Jupyter Lab is **enabled**. You can control this behavior:

```bash
# Start with Jupyter Lab enabled (default)
python y_social.py --host localhost --port 8080

# Disable Jupyter Lab for security
python y_social.py --host localhost --port 8080 --no_notebook
```

**Security Note:** For production deployments or security-sensitive environments, use the `--no_notebook` flag to disable Jupyter Lab functionality.

### Using Jupyter Lab with Experiments

1. **Start an experiment** from the admin panel
2. **Launch Jupyter Lab** for the experiment (button in experiment details)
3. **Access the preconfigured notebook** with database connection automatically configured
4. **Analyze your simulation data** using ySights

Each experiment gets its own isolated Jupyter Lab instance with:
- Automatic database connection via environment variable
- Sample notebook (`start_here.ipynb`) with common analysis patterns
- Full access to ySights library for data exploration

üìö **See the [ySights documentation](https://ysocialtwin.github.io/ysights/) for detailed tutorials and API reference**

---

## üê≥ Running with Docker

Docker is a platform for developing, shipping, and running applications in containers.

Don't want to deal with dependencies? `Y Social` provides a **Dockerized setup** that includes:
- **[Ollama](https://ollama.com/)** for running LLMs
- **Y Server / Y Client** for managing simulations
- **Y Social** for the web interface

### üì¶ **Building & Running the Docker Container**
```bash
docker-compose -f docker-compose.yml build
docker-compose up
```

#### ‚ö° **Enable GPU Support (NVIDIA Only)**
```bash
docker-compose -f docker-compose.yml -f docker-compose_gpu.yml build
docker-compose up --gpus all
```
üí° **Ensure you have the [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html) installed.**

üî¥ **Note:** MacOS does not support GPU pass-through in Docker.

---

## üõ† Technical Stack

### üîô **Backend**
- **Framework:** [Flask](https://flask.palletsprojects.com/en/2.0.x/)
- **Database:** SQLite / PostgreSQL (via SQLAlchemy)
- **LLM Interaction:** [Autogen](https://github.com/microsoft/autogen)
- **LLM Servers:** [Ollama](https://ollama.com/), [vLLM](https://github.com/vllm-project/vllm), or any OpenAI-compatible server
- **Text Analysis:** [NLTK](https://www.nltk.org/) (sentiment), [Perspective API](https://www.perspectiveapi.com/) (toxicity)
- **Feed Parsing:** [feedparser](https://github.com/kurtmckee/feedparser)

### üé® **Frontend**
- **Template:** [Friendkit](https://cssninja.io/product/friendkit)
- **Agent Avatars:** [Cartoon Set 15k](https://google.github.io/cartoonset/)


---

## üìÑ Further Information
- **Project Website:** [YSocialTwin.github.io](https://ysocialtwin.github.io/)
- **Research Paper:** [Y Social: A Digital Twin for Social Simulations](https://arxiv.org/abs/2408.00818)

---

## üìú License
This project, for what concerns the businsess logic, is licensed under the **GNU General Public License (GPL)**. See the [LICENSE](LICENSE) file for details.
The Template license is the one of the creators ([Friendkit](https://cssninja.io/product/friendkit)) 

üìå **If you use Y Social for research, please cite:**
```bibtex
@article{rossetti2024ysocial,
  title={Y Social: an LLM-powered Social Media Digital Twin},
  author={Rossetti, Giulio and Stella, Massimo and Cazabet, R√©my and
  Abramski, Katherine and Cau, Erica and Citraro, Salvatore and
  Failla, Andrea and Improta, Riccardo and Morini, Virginia and
  Pansanella, Virginia},
  journal={arXiv preprint arXiv:2408.00818},
  year={2024}
}
```

üöÄ **Start your social simulation journey with Y Social today!** üé≠

